<============masking both weights and gradients for retrain<============all masking statistics<============testing sparsity before retrain<===sparsity type is block_prune_filter<===layers to be pruned are [0.5, 0.5]sparsity at layer wh.0.weight is 0.9356971153846154sparsity at layer wh.1.weight is 0.9672679901123047sparsity at layer uh.0.weight is 0.9666061401367188sparsity at layer uh.1.weight is 0.9574050903320312sparsity at layer wz.0.weight is 0.9400540865384616sparsity at layer wz.1.weight is 0.9663839340209961sparsity at layer uz.0.weight is 0.9665336608886719sparsity at layer uz.1.weight is 0.9666461944580078sparsity at layer wr.0.weight is 0.9362479967948718sparsity at layer wr.1.weight is 0.9668674468994141sparsity at layer ur.0.weight is 0.9673175811767578sparsity at layer ur.1.weight is 0.9668312072753906overal compression rate is 28.906535356621106Decoding TIMIT_test output out_dnn2%WER 19.6 | 192 7215 | 82.7 12.9 4.4 2.5 19.8 99.0 | -0.646 | /home/dongpe/RNN/temp2/exp/TIMIT_GRU_mfcc/decode_TIMIT_test_out_dnn2/score_5/ctm_39phn.filt.sys-----Generating output files and plots ...OK