<============masking both weights and gradients for retrain<============all masking statistics<============testing sparsity before retrain<===sparsity type is block_prune_filter<===layers to be pruned are [0.8, 0.8]sparsity at layer wh.0.weight is 0.9774889823717948sparsity at layer wh.1.weight is 0.9890241622924805sparsity at layer uh.0.weight is 0.988377571105957sparsity at layer uh.1.weight is 0.9786930084228516sparsity at layer wz.0.weight is 0.9781149839743589sparsity at layer wz.1.weight is 0.9884700775146484sparsity at layer uz.0.weight is 0.9885692596435547sparsity at layer uz.1.weight is 0.9884624481201172sparsity at layer wr.0.weight is 0.9752353766025641sparsity at layer wr.1.weight is 0.9889860153198242sparsity at layer ur.0.weight is 0.9888153076171875sparsity at layer ur.1.weight is 0.9885921478271484overal compression rate is 79.50048663622071Decoding TIMIT_test output out_dnn2%WER 21.5 | 192 7215 | 80.8 14.1 5.2 2.6 21.9 99.5 | -0.392 | /home/dongpe/RNN/temp2/exp/TIMIT_GRU_mfcc/decode_TIMIT_test_out_dnn2/score_5/ctm_39phn.filt.sys-----Generating output files and plots ...OK