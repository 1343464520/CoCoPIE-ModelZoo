<============masking both weights and gradients for retrain<============all masking statistics<============testing sparsity before retrain<===sparsity type is block_prune_filter<===layers to be pruned are [0.9, 0.9]sparsity at layer wh.0.weight is 0.9744841746794872sparsity at layer wh.1.weight is 0.9914932250976562sparsity at layer uh.0.weight is 0.9910459518432617sparsity at layer uh.1.weight is 0.9748239517211914sparsity at layer wz.0.weight is 0.9633914262820513sparsity at layer wz.1.weight is 0.9915409088134766sparsity at layer uz.0.weight is 0.9917268753051758sparsity at layer uz.1.weight is 0.9913644790649414sparsity at layer wr.0.weight is 0.9607371794871795sparsity at layer wr.1.weight is 0.9918136596679688sparsity at layer ur.0.weight is 0.9916677474975586sparsity at layer ur.1.weight is 0.9912919998168945overal compression rate is 93.87177950868784Decoding TIMIT_test output out_dnn2%WER 21.7 | 192 7215 | 81.2 14.2 4.6 2.9 21.7 100.0 | -0.810 | /home/dongpe/RNN/temp0/pytorch-kaldi/exp/TIMIT_GRU_mfcc/decode_TIMIT_test_out_dnn2/score_4/ctm_39phn.filt.sys-----Generating output files and plots ...OK