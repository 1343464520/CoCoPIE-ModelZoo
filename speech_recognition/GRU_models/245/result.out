<============masking both weights and gradients for retrain<============all masking statistics<============testing sparsity before retrain<===sparsity type is block_prune_filter<===layers to be pruned are [0.9375, 0.9375]sparsity at layer wh.0.weight is 0.9929136618589743sparsity at layer wh.1.weight is 0.9965629577636719sparsity at layer uh.0.weight is 0.9962015151977539sparsity at layer uh.1.weight is 0.9929237365722656sparsity at layer wz.0.weight is 0.9920873397435898sparsity at layer wz.1.weight is 0.9962482452392578sparsity at layer uz.0.weight is 0.996429443359375sparsity at layer uz.1.weight is 0.996211051940918sparsity at layer wr.0.weight is 0.9920622996794872sparsity at layer wr.1.weight is 0.9964752197265625sparsity at layer ur.0.weight is 0.9963979721069336sparsity at layer ur.1.weight is 0.996312141418457overal compression rate is 245.59264018091176Decoding TIMIT_test output out_dnn2%WER 24.2 | 192 7215 | 78.7 16.1 5.2 3.1 24.4 99.5 | -0.540 | /home/dongpe/RNN/temp1/exp/TIMIT_GRU_mfcc/decode_TIMIT_test_out_dnn2/score_4/ctm_39phn.filt.sys-----Generating output files and plots ...OK